# kafka

## 基本概念
1. 采用 Scala 语言开发的一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统-2.8.0 及以后版本支持 KRaft 模式,可以脱离 ZK 运行
2. 而 Scala 是一种基于 JVM 的语言,因此 Kafka 需要 JVM 来运行
3. 一个分布式流式处理平台,它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用
4. 角色
   1. 消息系统
      1. 具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能
      2. 还提供了大多数消息系统难以实现的消息顺序性保障及回溯消费的功能
   2. 存储系统
      1. 消息持久化功能和多副本机制
      2. 持久化到磁盘上
   3. 流式处理平台
5. 基本模块
   1. ![](https://pic1.imgdb.cn/item/67876eccd0e0a243d4f47d59.png)
   2. 若干 Producer
   3. 若干 Consumer
   4. 一个 ZooKeeper 集群-负责集群元数据的管理、控制器的选举等操作
   5. 若干 Broker-服务代理节点-接收生产者发的消息,提供给消费者拉取
   6. 主题（Topic）
      1. 是一个逻辑上的概念,它还可以细分为多个分区,一个分区只属于单个主题
      2. Kafka 中的消息以主题为单位进行归类,生产者负责将消息发送到特定的主题
      3. （发送到 Kafka 集群中的每一条消息都要指定一个主题）,而消费者负责订阅主题并进行消费
   7. 分区（Partition）
      1. ![](https://pic1.imgdb.cn/item/67876f5ad0e0a243d4f47d8c.png)
      2. 一个分区只属于单个主题
      3. 同一主题下的不同分区包含的消息是不同的
      4. 分区在存储层面可以看作一个可追加的日志（Log）文件,消息在被追加到分区日志文件的时候都会分配一个特定的偏移量(offset)
      5. offset 是消息在分区中的唯一标识,Kafka 通过它来保证消息在分区内的顺序性-offset 并不跨越分区,也就是说,Kafka 保证的是分区有序而不是主题有序
   8. 多副本（Replica）机制
      1. ![](https://pic1.imgdb.cn/item/67876fd8d0e0a243d4f47dad.png)
      2. 通过增加副本数量可以提升容灾能力
      3. 副本之间是“一主多从”的关系,其中 leader 副本负责处理读写请求
      4. follower 副本只负责与 leader 副本的消息同步
      5. 从节点消息内容会延迟与主节点
      6. 副本处于不同的 broker 中,当 leader 副本出现故障时,从 follower 副本中重新选举新的 leader 副本对外提供服务
      7. AR（Assigned Replicas）-所有副本
      8. ISR（In-Sync Replicas）-所有与 leader 副本保持一定程度同步的副本（包括 leader 副本在内）
      9.  OSR（Out-of-Sync Replicas）-与 leader 副本同步滞后过多的副本（不包括 leader 副本）
      10. AR=ISR+OSR
      11. leader 副本负责维护和跟踪 ISR 集合中所有 follower 副本的滞后状态
          1. 当 follower 副本落后太多或失效时,从ISR中剔除
          2. 当OSR 集合中有 follower 副本“追上”了 leader 副本,则加入ISR
      12. 当 leader 副本发生故障时,只有在 ISR 集合中的副本才有资格被选举为新的 leader
      13. ![](https://pic1.imgdb.cn/item/678770ccd0e0a243d4f47e05.png)
      14. HW-高水位 High Watermark-消费者只能拉取到这个之前的消息
      15. LEO-Log End Offset,下一条要写入的消息位置
      16. 分区 ISR 集合中的每个副本都会维护自身的 LEO,而 ISR 集合中最小的 LEO 即为分区的 HW,对消费者而言只能消费 HW 之前的消息
      17. 既避免了同步机制造成的效率低下,也保证了leader宕机时,副本和客户端的消息同步不会有太大的偏差

## 模块
1. 生产
   1. KafkaProducer 是线程安全的,可以在多个线程中共享单个 KafkaProducer 实例,也可以将 KafkaProducer 实例进行池化来供其他线程调用
   2. 发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）
   3. 可重试的异常和不可重试的异常
   4. 可以配置重试次数
2. 序列化
   1. 生产者与消费者的序列化和反序列化方式需要一致
   2. 拦截器（Interceptor）--> 序列化器（Serializer）--> 分区器（Partitioner）(未指定分区号)-->broker
   3. 拦截器
      1. 生产拦截器
      2. 消费拦截器
3. 生产者结构
   1. ![](https://pic1.imgdb.cn/item/67877475d0e0a243d4f47f13.png)
   2. 整个生产者客户端由两个线程协调运行
      1. 主线程
         1. 在主线程中由 KafkaProducer 创建消息
         2. 然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator,也称为消息收集器）中
      1. Sender线程(发送线程)-从 RecordAccumulator 中获取消息并将其发送到 Kafka 中
   3. 消息累加器-RecordAccumulator
      1. 主要用来缓存消息以便 Sender 线程可以批量发送,减少网络I/O消耗
      2. 缓存的大小可以配置,默认32MB
      3. 如果生产者发送过快,会导致阻塞或异常,默认超时时间60秒
      4. 为每个分区都维护了一个双端队列
         1. 写入则追加到队尾
         2. 读取则从队头获取
         3. 队列中的内容就是 ProducerBatch-是一系列消息的集合,提高吞吐量
         4. 会维护一个BufferPool的内存区域来达到复用目的
   4. sender线程从消息累加器获取内容,同时从区间结构信息转为节点信息结构-应用逻辑层面到网络I/O层面的转换
   5. 发送前,还需要将节点信息结构包装成节点网络请求结构
      1. 发送前会再缓存一次(InFlightRequests),收到响应后会清理
      2. InFlightRequests会维护每个连接的最大请求数量
   6. 收到响应后会逐步清理
   7. 元数据信息
      1. 客户端缓存了不同主题对应的分区,主从节点,地址,端口信息
      2. 会从InFlightRequests挑选出负载最小的节点作为leastLoadedNode-通过这个节点发送元数据信息获取请求
   8. 重要参数
      1. acks
         1. 用来指定分区中必须要有多少个副本收到这条消息,之后生产者才会认为这条消息是成功写入的
         2. 默认值即为1。生产者发送消息之后,只要分区的 leader 副本成功写入消息,那么它就会收到来自服务端的成功响应
         3. acks = 1,是消息可靠性和吞吐量之间的折中方案。
         4. acks = 0。生产者发送消息之后不需要等待任何服务端的响应-可以获取最大吞吐量
         5. acks = -1 或 acks = all。生产者在消息发送之后,需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应
      2. max.request.size
         1. 生产者客户端能发送的消息的最大值,默认值为1048576B,即1MB
      3. retries和retry.backoff.ms
         1. 重试次数,默认0
         2. 重试间隔时间,默认值为100
         3. 如果强制要求消息顺序性,则需要将连接数限制(max.in.flight.requests.per.connection)为1,否则会出现乱序
      4. compression.type
         1. 指定消息的压缩方式,默认为不压缩-时间换空间
      5. connections.max.idle.ms
         1. 指定在多久之后关闭闲置的连接,默认9分钟
      6. linger.ms
         1. 生产者发送 ProducerBatch 之前等待更多消息加入消息累加器的时间,默认为0
         2. 生产者客户端会在 ProducerBatch 被填满或等待时间超过 linger.ms 值时发送出去.增大这个参数的值会增加消息的延迟,但是同时能提升一定的吞吐量
      7. receive.buffer.bytes
         1. 设置 Socket 接收消息缓冲区,默认32kb
      8. send.buffer.bytes
         1. 设置 Socket 发送消息缓冲区,默认128kb
      9. request.timeout.ms
         1. 配置 Producer 等待请求响应的最长时间,默认值为30秒
4. 消费
   1. 消费者与消费组
      1. ![](https://pic1.imgdb.cn/item/67878022d0e0a243d4f48504.png)
      2. 每个消费者都有一个对应的消费组
      3. 当消息发布到主题后,只会被投递给订阅它的每个消费组中的一个消费者
      4. 消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性,我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力
      5. 每一个分区只能被一个消费组中的一个消费者所消费
      6. 消费组是一个逻辑上的概念
      7. 消费者并非逻辑上的概念,它是实际的应用实例,它可以是一个线程,也可以是一个进程,也可以跨机器
      8. 支持2种消息投递模式
         1. 点对点（P2P,Point-to-Point）模式
            1. 同一个消费者组内的消费者共享消息
            2. 每条消息只被一个消费者处理-通过消费者组模拟实现
            3. 任务分发、负载均衡
         2. 发布/订阅（Pub/Sub）模式
            1. 多个消费者组独立消费-原生支持
            2. 日志分发、事件通知
   2. 订阅主题
      1. subscribe()
         1. 具有消费者自动再均衡的功能
         2. 在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系
         3. 当消费组内的消费者增加或减少时,分区分配关系会自动调整,以实现消费负载均衡及故障自动转移
      2. assign()
         1. 不具备消费者自动均衡的功能
   3. 基于拉模式
      1. 消费者主动向服务端发起请求来拉取消息
      2. 是一个不断轮询的过程,消费者所要做的就是重复地调用 poll() 方法,而 poll() 方法返回的是所订阅的主题（分区）上的一组消息
   4. 消费位移
      1. 消费者完成消费后的位置在服务端中记录下来的动作,便于在客户端崩溃后重新开始消费
      2. 默认的消费位移的提交方式是自动提交-定期提交-默认5秒-可以设置为关闭
      3. 消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交
      4. 动作是在 poll() 方法的逻辑里完成的,在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交,如果可以,那么就会提交上一次轮询的位移
      5. 存在重复消费和消息丢失的问题
      6. 提供了手动提交的方式
         1. 同步提交-commitSync()-每消费一条消息就提交一次消费位移
         2. 异步提交-commitAsync()
            1. 在执行的时候消费者线程不会被阻塞,可能在提交消费位移的结果还未返回之前就开始了新一次的拉取操作
            2. 可以设置一个递增的序号来维护异步提交的顺序
      7. 可以控制或关闭消费
   5. 指定位移消费
      1. 当消费者查找不到所记录的消费位移时,可根据配置从特定位置读取消息
      2. 默认值为“latest”，表示从分区末尾开始消费消息
      3. seek() 方法可以指定区,指定时间,跨topic,跨存储介质读取消息-需要先获取分区信息
   6. 再均衡
      1. 再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者
      2. 再均衡发生期间，消费组内的消费者是无法读取消息的
      3. 再均衡监听器会处理当前消费位移的提交
   7. 消费拦截器
      1. 拦截链
      2. 如果在拦截链中某个拦截器执行失败，那么下一个拦截器会接着从上一个执行成功的拦截器继续执行
   8. 消费者多线程实现
      1. 消费者有一个acquire() 方法，用来检测当前是否只有一个线程在操作-轻量级锁
      2. 可以利用线程池结合滑动窗口原理
   9. 重要参数
      1. fetch.min.bytes-Consumer 在一次拉取请求中从Kafka中拉取的最小数据量-默认值为1（B）
      2. fetch.max.bytes-Consumer 在一次拉取请求中从Kafka中拉取的最大数据量-最大50 MB
      3. max.poll.records-在一次拉取请求中拉取的最大消息数，默认值为500（条）
      4. request.timeout.ms-Consumer 等待请求响应的最长时间，默认值为30000（ms）
      5. metadata.max.age.ms-配置元数据的过期时间，默认值为300000（ms），即5分钟
      6. isolation.level-配置消费者的事务隔离级别-默认情况下为“read_uncommitted”，即可以消费到 HW（High Watermark）处的位置
5. 主题
   1. ![](https://pic1.imgdb.cn/item/678788d2d0e0a243d4f48805.png)
   2. 主题和分区都是逻辑上的概念，分区可以有一至多个副本
   3. 每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment）
   4. 每个日志分段还可以细分为索引文件、日志存储文件和快照文件等
   5. 主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在
   6. 同一个分区中的多个副本必须分布在不同的 broker 中，这样才能提供有效的数据冗余-实质上是分区数与副本因子的乘积
   7. 主题名不要包含“.”或“_”字符系统会将"."转为"_"-也不推荐（虽然可以这样做）使用双下画线“__”开头-系统的内部主题命名方式
   8. 目前 Kafka 只支持增加分区数而不支持减少分区数
      1. 如果减少分区,已有的数据要分配到更少的分区,破坏了顺序性
         1. 增加分区时,旧数据不会再分配,新数据会写入新分区
      2. 消费的偏移量被破坏
      3. 同时需要考虑其他细节,可靠性无法保证,价值较小
      4. 如果数据量较大,服务可用性被影响
      5. 分区过多的处理
         1. 合并topic
         2. 数据归档
         3. 重建topic
   9.  删除主题实际是在zookeeper中创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态
6. KafkaAdminClient-使用API方法集成到内部系统中
7. 优先副本的选举
   1. 为了能够有效地治理负载失衡的情况
   2. 优先副本是指在AR集合列表中的第一个副本
   3. 负载均衡
      1. 为了避免某些 Broker 上的 Leader 副本过多
      2. 通过将分区的 Leader 切换回优先副本确保 Leader 均匀分布在集群中的各个 Broker 上
   4. 故障恢复
      1. 当 Broker 发生故障时，Kafka 会自动将分区的 Leader 切换到其他副本
      2. 故障恢复后，可以通过优先副本选举将 Leader 切换回原来的 Broker
   5. 优先副本选举-将分区的 Leader 切换回优先副本的过程
   6. Kafka 中可以提供分区自动平衡的功能-默认是true-建议关闭-因为时长不可控制,在关键高峰节点对服务可用性有影响-分区不均衡的代价可以忍受
   7. 可以主动全量均衡,但更建议使用小批量手动执行的方式
   8. 优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响
8. 分区重分配
   1. broker层面的新增或减少
   2. 单个集群内部的数据复制
   3. 先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的 leader 副本那里复制所有的数据
   4. 复制完成后,控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）-复制支持配置限流
   5. 降低重分配的粒度，分成多个小批次来执行，以此来将负面的影响降到最低
   6. 如果要将某个 broker 下线，那么在执行分区重分配动作之前最好先关闭或重启 broker,来释放节点
9.  分区设置
   1. 分区数越多吞吐量越高这个命题不成立
   2. 有些应用场景会要求主题中的消息都能保证顺序性
      1. 这种情况下在创建主题时可以设定分区数为1
      2. 通过分区有序性的这一特性来达到主题有序性的目的
   3. 分区不可设置过多
      1. 分区数会占用文件描述符，而一个进程所能支配的文件描述符是有限的，这也是通常所说的文件句柄的开销
      2. 分区数过大会导致follower 副本中选举时间过长
         1. 当 broker 发生故障时,leader 副本所属宿主的 broker 节点上的所有分区将暂时处于不可用的状态
         2. 此时 Kafka 会自动在其他的 follower 副本中选举出新的 leader 用于接收外部客户端的请求
         3. 整个过程由 Kafka 控制器负责完成。分区在进行 leader 角色切换的过程中会变得不可用
      3. 分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长
      4. 主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间

## 工具
1. Kafka Connect
   1. 支持将外部数据导入kafka或导出
   2. 支持REST 接口
   3. 支持独立模式（standalone）和分布式模式（distributed）
   4. 分布式和可扩展性-分布式模式天然地结合了 Kafka 提供的负载均衡和故障转移功能，能够自动在多个节点机器上平衡负载
   5. 流式计算/批处理的集成
2. Kafka Mirror Maker
   1. ![](https://pic1.imgdb.cn/item/6788a2ecd0e0a243d4f4be9c.png)
   2. 用于在两个集群之间同步数据的一个工具，其实现原理是通过从源集群中消费消息，然后将消息生产到目标集群中，也就是普通的生产和消费消息
   3. Kafka 与 Kafka 之间的数据复制
   4. 跨集群之间的数据复制
3. Kafka Streams
   1. 用于处理和分析数据的客户端库。它先把存储在 Kafka 中的数据进行处理和分析，然后将最终所得的数据结果回写到 Kafka 或发送到外部系统
4. Kafka监控
   1. ![](https://pic1.imgdb.cn/item/6788a2ecd0e0a243d4f4be9d.png)
   2. 消息堆积是消息中间件的一大特色，消息中间件的流量削峰、冗余存储等功能正是得益于消息中间件的消息堆积能力
   3. 影响上下游的业务，堆积过多有可能造成磁盘爆满，或者触发日志清除操作而造成消息丢失的情况
5. Spark
   1. 用来实现快速且通用的集群计算的平台,包含众多不同功能的组件
   2. 使用 Scala 语言开发，支持 Scala、Java、Python、R 语言相关的 API，运行于 JVM 之上
   3. Spark 基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性
   4. Kafka作为数据源进入Spark Streaming,然后进行复杂算法的处理,然后存储到不同的方式中

## 原理

### 日志文件

### 存储层

### 协议

### 时间轮

### 延时操作

### 控制器

### 服务端参数

### 消费端分区分配策略

### 消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）

### 事务

### 多副本机制

### 可靠性

### 扩展

## 其他消息组件
1. pulsar

2. rocketMq
