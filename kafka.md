# kafka

## 基本概念
1. 采用 Scala 语言开发的一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统-2.8.0 及以后版本支持 KRaft 模式,可以脱离 ZK 运行
2. 而 Scala 是一种基于 JVM 的语言,因此 Kafka 需要 JVM 来运行
3. 一个分布式流式处理平台,它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用
4. 角色
   1. 消息系统
      1. 具备系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等功能
      2. 还提供了大多数消息系统难以实现的消息顺序性保障及回溯消费的功能
   2. 存储系统
      1. 消息持久化功能和多副本机制
      2. 持久化到磁盘上
   3. 流式处理平台
5. 基本模块
   1. ![](https://pic1.imgdb.cn/item/67876eccd0e0a243d4f47d59.png)
   2. 若干 Producer
   3. 若干 Consumer
   4. 一个 ZooKeeper 集群-负责集群元数据的管理、控制器的选举等操作
   5. 若干 Broker-服务代理节点-接收生产者发的消息,提供给消费者拉取
   6. 主题（Topic）
      1. 是一个逻辑上的概念,它还可以细分为多个分区,一个分区只属于单个主题
      2. Kafka 中的消息以主题为单位进行归类,生产者负责将消息发送到特定的主题
      3. （发送到 Kafka 集群中的每一条消息都要指定一个主题）,而消费者负责订阅主题并进行消费
   7. 分区（Partition）
      1. ![](https://pic1.imgdb.cn/item/67876f5ad0e0a243d4f47d8c.png)
      2. 一个分区只属于单个主题
      3. 同一主题下的不同分区包含的消息是不同的
      4. 分区在存储层面可以看作一个可追加的日志（Log）文件,消息在被追加到分区日志文件的时候都会分配一个特定的偏移量(offset)
      5. offset 是消息在分区中的唯一标识,Kafka 通过它来保证消息在分区内的顺序性-offset 并不跨越分区,也就是说,Kafka 保证的是分区有序而不是主题有序
   8. 多副本（Replica）机制
      1. ![](https://pic1.imgdb.cn/item/67876fd8d0e0a243d4f47dad.png)
      2. 通过增加副本数量可以提升容灾能力
      3. 副本之间是“一主多从”的关系,其中 leader 副本负责处理读写请求
      4. follower 副本只负责与 leader 副本的消息同步
      5. 从节点消息内容会延迟与主节点
      6. 副本处于不同的 broker 中,当 leader 副本出现故障时,从 follower 副本中重新选举新的 leader 副本对外提供服务
      7. AR（Assigned Replicas）-所有副本
      8. ISR（In-Sync Replicas）-所有与 leader 副本保持一定程度同步的副本（包括 leader 副本在内）
      9.  OSR（Out-of-Sync Replicas）-与 leader 副本同步滞后过多的副本（不包括 leader 副本）
      10. AR=ISR+OSR
      11. leader 副本负责维护和跟踪 ISR 集合中所有 follower 副本的滞后状态
          1. 当 follower 副本落后太多或失效时,从ISR中剔除
          2. 当OSR 集合中有 follower 副本“追上”了 leader 副本,则加入ISR
      12. 当 leader 副本发生故障时,只有在 ISR 集合中的副本才有资格被选举为新的 leader
      13. ![](https://pic1.imgdb.cn/item/678770ccd0e0a243d4f47e05.png)
      14. HW-高水位 High Watermark-消费者只能拉取到这个之前的消息
      15. LEO-Log End Offset,下一条要写入的消息位置
      16. 分区 ISR 集合中的每个副本都会维护自身的 LEO,而 ISR 集合中最小的 LEO 即为分区的 HW,对消费者而言只能消费 HW 之前的消息
      17. 既避免了同步机制造成的效率低下,也保证了leader宕机时,副本和客户端的消息同步不会有太大的偏差

## 模块
1. 生产
   1. KafkaProducer 是线程安全的,可以在多个线程中共享单个 KafkaProducer 实例,也可以将 KafkaProducer 实例进行池化来供其他线程调用
   2. 发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）
   3. 可重试的异常和不可重试的异常
   4. 可以配置重试次数
2. 序列化
   1. 生产者与消费者的序列化和反序列化方式需要一致
   2. 拦截器（Interceptor）--> 序列化器（Serializer）--> 分区器（Partitioner）(未指定分区号)-->broker
   3. 拦截器
      1. 生产拦截器
      2. 消费拦截器
3. 生产者结构
   1. ![](https://pic1.imgdb.cn/item/67877475d0e0a243d4f47f13.png)
   2. 整个生产者客户端由两个线程协调运行
      1. 主线程
         1. 在主线程中由 KafkaProducer 创建消息
         2. 然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（RecordAccumulator,也称为消息收集器）中
      1. Sender线程(发送线程)-从 RecordAccumulator 中获取消息并将其发送到 Kafka 中
   3. 消息累加器-RecordAccumulator
      1. 主要用来缓存消息以便 Sender 线程可以批量发送,减少网络I/O消耗
      2. 缓存的大小可以配置,默认32MB
      3. 如果生产者发送过快,会导致阻塞或异常,默认超时时间60秒
      4. 为每个分区都维护了一个双端队列
         1. 写入则追加到队尾
         2. 读取则从队头获取
         3. 队列中的内容就是 ProducerBatch-是一系列消息的集合,提高吞吐量
         4. 会维护一个BufferPool的内存区域来达到复用目的
   4. sender线程从消息累加器获取内容,同时从区间结构信息转为节点信息结构-应用逻辑层面到网络I/O层面的转换
   5. 发送前,还需要将节点信息结构包装成节点网络请求结构
      1. 发送前会再缓存一次(InFlightRequests),收到响应后会清理
      2. InFlightRequests会维护每个连接的最大请求数量
   6. 收到响应后会逐步清理
   7. 元数据信息
      1. 客户端缓存了不同主题对应的分区,主从节点,地址,端口信息
      2. 会从InFlightRequests挑选出负载最小的节点作为leastLoadedNode-通过这个节点发送元数据信息获取请求
   8. 重要参数
      1. acks
         1. 用来指定分区中必须要有多少个副本收到这条消息,之后生产者才会认为这条消息是成功写入的
         2. 默认值即为1.生产者发送消息之后,只要分区的 leader 副本成功写入消息,那么它就会收到来自服务端的成功响应
         3. acks = 1,是消息可靠性和吞吐量之间的折中方案.
         4. acks = 0.生产者发送消息之后不需要等待任何服务端的响应-可以获取最大吞吐量
         5. acks = -1 或 acks = all.生产者在消息发送之后,需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应
      2. max.request.size
         1. 生产者客户端能发送的消息的最大值,默认值为1048576B,即1MB
      3. retries和retry.backoff.ms
         1. 重试次数,默认0
         2. 重试间隔时间,默认值为100
         3. 如果强制要求消息顺序性,则需要将连接数限制(max.in.flight.requests.per.connection)为1,否则会出现乱序
      4. compression.type
         1. 指定消息的压缩方式,默认为不压缩-时间换空间
      5. connections.max.idle.ms
         1. 指定在多久之后关闭闲置的连接,默认9分钟
      6. linger.ms
         1. 生产者发送 ProducerBatch 之前等待更多消息加入消息累加器的时间,默认为0
         2. 生产者客户端会在 ProducerBatch 被填满或等待时间超过 linger.ms 值时发送出去.增大这个参数的值会增加消息的延迟,但是同时能提升一定的吞吐量
      7. receive.buffer.bytes
         1. 设置 Socket 接收消息缓冲区,默认32kb
      8. send.buffer.bytes
         1. 设置 Socket 发送消息缓冲区,默认128kb
      9. request.timeout.ms
         1. 配置 Producer 等待请求响应的最长时间,默认值为30秒
4. 消费
   1. 消费者与消费组
      1. ![](https://pic1.imgdb.cn/item/67878022d0e0a243d4f48504.png)
      2. 每个消费者都有一个对应的消费组
      3. 当消息发布到主题后,只会被投递给订阅它的每个消费组中的一个消费者
      4. 消费者与消费组这种模型可以让整体的消费能力具备横向伸缩性,我们可以增加（或减少）消费者的个数来提高（或降低）整体的消费能力
      5. 每一个分区只能被一个消费组中的一个消费者所消费
      6. 消费组是一个逻辑上的概念
      7. 消费者并非逻辑上的概念,它是实际的应用实例,它可以是一个线程,也可以是一个进程,也可以跨机器
      8. 支持2种消息投递模式
         1. 点对点（P2P,Point-to-Point）模式
            1. 同一个消费者组内的消费者共享消息
            2. 每条消息只被一个消费者处理-通过消费者组模拟实现
            3. 任务分发、负载均衡
         2. 发布/订阅（Pub/Sub）模式
            1. 多个消费者组独立消费-原生支持
            2. 日志分发、事件通知
   2. 订阅主题
      1. subscribe()
         1. 具有消费者自动再均衡的功能
         2. 在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系
         3. 当消费组内的消费者增加或减少时,分区分配关系会自动调整,以实现消费负载均衡及故障自动转移
      2. assign()
         1. 不具备消费者自动均衡的功能
   3. 基于拉模式
      1. 消费者主动向服务端发起请求来拉取消息
      2. 是一个不断轮询的过程,消费者所要做的就是重复地调用 poll() 方法,而 poll() 方法返回的是所订阅的主题（分区）上的一组消息
   4. 消费位移
      1. 消费者完成消费后的位置在服务端中记录下来的动作,便于在客户端崩溃后重新开始消费
      2. 默认的消费位移的提交方式是自动提交-定期提交-默认5秒-可以设置为关闭
      3. 消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交
      4. 动作是在 poll() 方法的逻辑里完成的,在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交,如果可以,那么就会提交上一次轮询的位移
      5. 存在重复消费和消息丢失的问题
      6. 提供了手动提交的方式
         1. 同步提交-commitSync()-每消费一条消息就提交一次消费位移
         2. 异步提交-commitAsync()
            1. 在执行的时候消费者线程不会被阻塞,可能在提交消费位移的结果还未返回之前就开始了新一次的拉取操作
            2. 可以设置一个递增的序号来维护异步提交的顺序
      7. 可以控制或关闭消费
   5. 指定位移消费
      1. 当消费者查找不到所记录的消费位移时,可根据配置从特定位置读取消息
      2. 默认值为“latest”,表示从分区末尾开始消费消息
      3. seek() 方法可以指定区,指定时间,跨topic,跨存储介质读取消息-需要先获取分区信息
   6. 再均衡
      1. 再均衡是指分区的所属权从一个消费者转移到另一消费者的行为,它为消费组具备高可用性和伸缩性提供保障,使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者
      2. 再均衡发生期间,消费组内的消费者是无法读取消息的
      3. 再均衡监听器会处理当前消费位移的提交
   7. 消费拦截器
      1. 拦截链
      2. 如果在拦截链中某个拦截器执行失败,那么下一个拦截器会接着从上一个执行成功的拦截器继续执行
   8. 消费者多线程实现
      1. 消费者有一个acquire() 方法,用来检测当前是否只有一个线程在操作-轻量级锁
      2. 可以利用线程池结合滑动窗口原理
   9. 重要参数
      1. fetch.min.bytes-Consumer 在一次拉取请求中从Kafka中拉取的最小数据量-默认值为1（B）
      2. fetch.max.bytes-Consumer 在一次拉取请求中从Kafka中拉取的最大数据量-最大50 MB
      3. max.poll.records-在一次拉取请求中拉取的最大消息数,默认值为500（条）
      4. request.timeout.ms-Consumer 等待请求响应的最长时间,默认值为30000（ms）
      5. metadata.max.age.ms-配置元数据的过期时间,默认值为300000（ms）,即5分钟
      6. isolation.level-配置消费者的事务隔离级别-默认情况下为“read_uncommitted”,即可以消费到 HW（High Watermark）处的位置
5. 主题
   1. ![](https://pic1.imgdb.cn/item/678788d2d0e0a243d4f48805.png)
   2. 主题和分区都是逻辑上的概念,分区可以有一至多个副本
   3. 每个副本对应一个日志文件,每个日志文件对应一至多个日志分段（LogSegment）
   4. 每个日志分段还可以细分为索引文件、日志存储文件和快照文件等
   5. 主题和分区都是提供给上层用户的抽象,而在副本层面或更加确切地说是 Log 层面才有实际物理上的存在
   6. 同一个分区中的多个副本必须分布在不同的 broker 中,这样才能提供有效的数据冗余-实质上是分区数与副本因子的乘积
   7. 主题名不要包含“.”或“_”字符系统会将"."转为"_"-也不推荐（虽然可以这样做）使用双下画线“__”开头-系统的内部主题命名方式
   8. 目前 Kafka 只支持增加分区数而不支持减少分区数
      1. 如果减少分区,已有的数据要分配到更少的分区,破坏了顺序性
         1. 增加分区时,旧数据不会再分配,新数据会写入新分区
      2. 消费的偏移量被破坏
      3. 同时需要考虑其他细节,可靠性无法保证,价值较小
      4. 如果数据量较大,服务可用性被影响
      5. 分区过多的处理
         1. 合并topic
         2. 数据归档
         3. 重建topic
   9.  删除主题实际是在zookeeper中创建一个与待删除主题同名的节点,以此标记该主题为待删除的状态
6. KafkaAdminClient-使用API方法集成到内部系统中
7. 优先副本的选举
   1. 为了能够有效地治理负载失衡的情况
   2. 优先副本是指在AR集合列表中的第一个副本
   3. 负载均衡
      1. 为了避免某些 Broker 上的 Leader 副本过多
      2. 通过将分区的 Leader 切换回优先副本确保 Leader 均匀分布在集群中的各个 Broker 上
   4. 故障恢复
      1. 当 Broker 发生故障时,Kafka 会自动将分区的 Leader 切换到其他副本
      2. 故障恢复后,可以通过优先副本选举将 Leader 切换回原来的 Broker
   5. 优先副本选举-将分区的 Leader 切换回优先副本的过程
   6. Kafka 中可以提供分区自动平衡的功能-默认是true-建议关闭-因为时长不可控制,在关键高峰节点对服务可用性有影响-分区不均衡的代价可以忍受
   7. 可以主动全量均衡,但更建议使用小批量手动执行的方式
   8. 优先副本的选举操作也要注意避开业务高峰期,以免带来性能方面的负面影响
8. 分区重分配
   1. broker层面的新增或减少
   2. 单个集群内部的数据复制
   3. 先通过控制器为每个分区添加新副本（增加副本因子）,新的副本将从分区的 leader 副本那里复制所有的数据
   4. 复制完成后,控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）-复制支持配置限流
   5. 降低重分配的粒度,分成多个小批次来执行,以此来将负面的影响降到最低
   6. 如果要将某个 broker 下线,那么在执行分区重分配动作之前最好先关闭或重启 broker,来释放节点
9.  分区设置
   1. 分区数越多吞吐量越高这个命题不成立
   2. 有些应用场景会要求主题中的消息都能保证顺序性
      1. 这种情况下在创建主题时可以设定分区数为1
      2. 通过分区有序性的这一特性来达到主题有序性的目的
   3. 分区不可设置过多
      1. 分区数会占用文件描述符,而一个进程所能支配的文件描述符是有限的,这也是通常所说的文件句柄的开销
      2. 分区数过大会导致follower 副本中选举时间过长
         1. 当 broker 发生故障时,leader 副本所属宿主的 broker 节点上的所有分区将暂时处于不可用的状态
         2. 此时 Kafka 会自动在其他的 follower 副本中选举出新的 leader 用于接收外部客户端的请求
         3. 整个过程由 Kafka 控制器负责完成.分区在进行 leader 角色切换的过程中会变得不可用
      3. 分区数越多也会让 Kafka 的正常启动和关闭的耗时变得越长
      4. 主题的分区数越多不仅会增加日志清理的耗时,而且在被删除时也会耗费更多的时间

## 工具
1. Kafka Connect
   1. 支持将外部数据导入kafka或导出
   2. 支持REST 接口
   3. 支持独立模式（standalone）和分布式模式（distributed）
   4. 分布式和可扩展性-分布式模式天然地结合了 Kafka 提供的负载均衡和故障转移功能,能够自动在多个节点机器上平衡负载
   5. 流式计算/批处理的集成
2. Kafka Mirror Maker
   1. ![](https://pic1.imgdb.cn/item/6788a2ecd0e0a243d4f4be9c.png)
   2. 用于在两个集群之间同步数据的一个工具,其实现原理是通过从源集群中消费消息,然后将消息生产到目标集群中,也就是普通的生产和消费消息
   3. Kafka 与 Kafka 之间的数据复制
   4. 跨集群之间的数据复制
3. Kafka Streams
   1. 用于处理和分析数据的客户端库.它先把存储在 Kafka 中的数据进行处理和分析,然后将最终所得的数据结果回写到 Kafka 或发送到外部系统
4. Kafka监控
   1. ![](https://pic1.imgdb.cn/item/6788a2ecd0e0a243d4f4be9d.png)
   2. 消息堆积是消息中间件的一大特色,消息中间件的流量削峰、冗余存储等功能正是得益于消息中间件的消息堆积能力
   3. 影响上下游的业务,堆积过多有可能造成磁盘爆满,或者触发日志清除操作而造成消息丢失的情况
5. Spark
   1. 用来实现快速且通用的集群计算的平台,包含众多不同功能的组件
   2. 使用 Scala 语言开发,支持 Scala、Java、Python、R 语言相关的 API,运行于 JVM 之上
   3. Spark 基于内存计算,提高了在大数据环境下数据处理的实时性,同时保证了高容错性和高可伸缩性
   4. Kafka作为数据源进入Spark Streaming,然后进行复杂算法的处理,然后存储到不同的方式中

## 原理

### 日志文件
1. 目录
   1. ![](https://pic1.imgdb.cn/item/6788bb9cd0e0a243d4f4cb79.png)
   2. 一个分区对应一个日志（Log）
   3. 将 Log 切分为多个 LogSegment
   4. Log 和 LogSegment 也不是纯粹物理意义上的概念
      1. Log 在物理上只以文件夹的形式存储
      2. 每个 LogSegment 对应于磁盘上的一个日志文件和两个索引文件,以及可能的其他文件
   5. 向 Log 中追加消息时是顺序写入的,只有最后一个 LogSegment 才能执行写入操作,在此之前所有的 LogSegment 都不能写入数据
   6. 随着消息的不断写入,当 activeSegment(当前活跃的日志分段) 满足一定的条件时,就需要创建新的 activeSegment
   7. Kafka 服务第一次启动的时候,会在根目录创建相关文件
   8. 消费位移第一次提交时会在Kafka 内部的主题创建文件
2. 日志格式/消息格式
   1. v0-Message Set
   2. v1-增加timestamp 字段
   3. v2
      1. 引入了变长整型（Varints）-Varints 是使用一个或多个字节来序列化整数的一种方法.数值越小,其占用的字节数就越少
      2. ZigZag 编码-以一种锯齿形（zig-zags）的方式来回穿梭正负整数,将带符号整数映射为无符号整数,这样可以使绝对值较小的负数仍然享有较小的 Varints 编码值
      3. Record Batch
      4. 支持事务、幂等性
   4. 消息压缩-将多条消息一起进行压缩,可以保证较好的压缩效果
3. 日志索引
   1. 偏移量索引文件
      1. 用来建立消息偏移量（offset）到物理地址之间的映射关系,方便快速定位消息所在的物理文件位置
      2. 偏移量是单调递增的
      3. 使用二分查找法来快速定位偏移量的位置
      4. ![](https://pic1.imgdb.cn/item/6788bdfbd0e0a243d4f4cc6c.png)
      5. relativeOffset：相对偏移量,表示消息相对于 baseOffset 的偏移量-相对偏移量只占用1个字节,更节省空间
      6. position：消息的物理地址-消息在日志分段文件中对应的物理位置
      7. Kafka 的每个日志对象中使用了 ConcurrentSkipListMap 来保存各个日志分段,每个日志分段的 baseOffset 作为 key,这样可以根据指定偏移量来快速定位到消息所在的日志分段-用了跳跃表的结构
   2. 时间戳索引文件
      1. ![](https://pic1.imgdb.cn/item/6788bdfbd0e0a243d4f4cc6d.png)
      2. 根据指定的时间戳（timestamp）来查找对应的偏移量信息
      3. 保持严格的单调递增
      4. 还需要根据偏移量索引文件来进行再次定位
   3. 索引文件以稀疏索引（sparse index）的方式构造-并不保证每个消息在索引文件中都有对应的索引项
   4. 稀疏索引通过 MappedByteBuffer 将索引文件映射到内存中,以加快索引的查询速度
   5. 日志分段文件达到一定的条件时需要进行切分
   6. 对非当前活跃的日志分段而言,只提供只读
   7. 对当前活跃的日志分段,支持读写
4. 日志清理
   1. 日志删除（Log Retention）
      1. 按照一定的保留策略直接删除不符合条件的日志分段-默认配置
      2. 日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件
      3. 保留策略
         1. 基于时间
            1. 检查当前日志文件中是否有保留时间超过设定的阈值
            2. 根据日志分段中最大的时间戳 largestTimeStamp 来计算的
            3. 如果是删除全部日志分段,则会新建一个活跃日志分段,用于接收消息的写入
            4. 从 Log 对象中所维护日志分段的跳跃表中移除待删除的日志分段,确保没有线程进行读取
            5. 文件添加上“.deleted”的后缀
            6. 有一个延迟任务来删除对应文件
         2. 基于日志大小
            1. 检查当前日志的大小是否超过设定的阈值
            2. 计算日志文件的总大小 size 和 retentionSize 的差值 diff,即计算需要删除的日志总大小
         3. 基于日志起始偏移量
            1. 依据是某日志分段的下一个日志分段的起始偏移量 baseOffset 是否小于等于 logStartOffset,若是,则可以删除此日志分段
   2. 日志压缩/瘦身（Log Compaction）
      1. ![](https://pic1.imgdb.cn/item/6788bf5dd0e0a243d4f4cd1d.png)
      2. 针对每个消息的 key 进行整合,对于有相同 key 的不同 value 值,只保留最后一个版本
      3. 需要区分不是消息压缩（Message Compression）-类比于 Redis 中的 RDB 的持久化模式-AOF
      4. checkpoint文件记录瘦身位置信息
      5. 日志清理线程会使用一个名为“SkimpyOffsetMap”的对象来构建 key 与 offset 的映射关系的哈希表
      6. 日志清理需要遍历两次日志文件
         1. 第一次记录信息
         2. 第二次检查数据是否要保留
      7. 墓碑消息（tombstone）
         1. 针对需要清理的数据,value设置为null
         2. 日志清理线程发现墓碑消息时会先进行常规的清理,并保留墓碑消息一段时间
      8. 针对日志分段进行分组进行瘦身
         1. 同一个组的多个日志分段清理过后,只会生成一个新的日志分段
         2. ![](https://pic1.imgdb.cn/item/6788bf5dd0e0a243d4f4cd1e.png)
         3. xxx.log-->xxx.log.clean-将每个日志分组中需要保留的消息复制到一个以“.clean”为后缀的临时文件中
         4. xxx.log.clean--->xxx.log-->xxx.log.swap-Log Compaction 过后将“.clean”的文件修改为“.swap”后缀的文件
         5. 删除原本的日志文件,最后才把文件的“.swap”后缀去掉

### 存储层
1. 顺序写盘
   1. Kafka 在设计时采用了文件追加的方式来写入消息,即只能在日志文件的尾部追加新的消息,并且也不允许修改已写入的消息
   2. 操作系统可以针对线性读写做深层次的优化
      1. 预读-read-ahead,提前将一个比较大的磁盘块读入内存
      2. 后写-write-behind,将很多小的逻辑写操作合并起来组成一个大的物理写操作
2. 页缓存
   1. 操作系统实现的一种主要的磁盘缓存,以此用来减少对磁盘 I/O 的操作
   2. kafka本身不在进程内缓存数据,而是直接使用文件系统并依赖于缓存页交互-和mysql redis等一致
   3. 通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间
   4. 将维护页缓存和文件之间的一致性交由操作系统来负责,简化了代码-即使 Kafka 服务重启,页缓存还是会保持有效,不用关心应用缓存
   5. 由操作系统来维护刷盘时机-虽然支持同步刷盘,但影响可用性
      1. 消息的可靠性应该由多副本机制来保障,而不是由同步刷盘这种严重影响性能的行为来保障
3. 可以将swap 分区调小
4. 磁盘I/O流程
   1. ![](https://pic1.imgdb.cn/item/6788d463d0e0a243d4f4d824.png)
   2. NOOP
      1. No Operation
      2. 实现了最简单的 FIFO队列,所有 I/O 请求大致按照先来后到的顺序进行操作做了相邻 I/O 请求的合并
   3. CFQ
      1. 默认策略
      2. Completely Fair Queuing
      3. 按照 I/O 请求的地址进行排序,而不是按照先来后到的顺序进行响应
      4. CFQ 为每个进程单独创建一个队列来管理该进程所产生的请求
      5. 各队列之间的调度使用时间片进行调度,以此来保证每个进程都能被很好地分配到 I/O 带宽
      6. 缺点:先来的 I/O 请求并不一定能被满足,可能会出现“饿死”的情况
   4. DEADLINE
      1. 解决了 I/O 请求“饿死”的极端情况
      2. DEADLINE 额外分别为读 I/O 和写 I/O 提供了 FIFO 队列,读请求的优先级高
      3. FIFO(Read) > FIFO(Write) > CFQ
   5. ANTICIPATORY
      1. 满足随机 I/O 和顺序 I/O 混合的场景
      2. 通过增加等待时间来获得更高的性能
5. 零拷贝
   1. Zero-Copy
   2. 将数据直接从磁盘文件复制到网卡设备中,而不需要经由应用程序之手
   3. 减少了内核和用户模式之间的上下文切换

### 协议
1. 自定义了一组基于 TCP 的二进制协议,类似于API概念
2. 在目前的 Kafka 2.0.0 中,一共包含了43种协议类型
3. 每种协议类型都有对应的请求（Request）和响应（Response）,它们都遵守特定的协议模式.每种类型的 Request 都包含相同结构的协议请求头（RequestHeader）和不同结构的协议请求体（RequestBody）

### 时间轮
1. ![](https://pic1.imgdb.cn/item/6788d56ed0e0a243d4f4d84f.png)
2. Kafka 中存在大量的延时操作,比如延时生产、延时拉取和延时删除等
3. 并没有使用 JDK 自带的 Timer 或 DelayQueue 来实现延时的功能,而是基于时间轮的概念自定义实现了一个用于延时功能的定时器（SystemTimer）
4. 平均时间复杂度为 O(nlogn)-JDK 中 Timer 和 DelayQueue 的插入和删除操作的,并不能满足 Kafka 的高性能要求
5. 时间复杂度都降为 O(1)-基于时间轮可以将插入和删除操作
6. 但还是使用了DelayQueue 专门负责时间推进的任务
   1. 使用DelayQueue可以避免无效计数
   2. 做最擅长的时间推进工作
7. 底层采用数组实现,数组中的每个元素可以存放一个定时任务列表（TimerTaskList）
8. TimerTaskList 是一个环形的双向链表,链表中的每一项表示的都是定时任务项（TimerTaskEntry）,其中封装了真正的定时任务（TimerTask）
   1. 存在一个哨兵节点（sentinel）-可以简化边界条件-作为第一个节点,无其他附加数据
9. 时间轮是多级的,低一级的全长耗时是高一级的单位时间
10. kafka只持有第一层时间轮的引用,各个时间轮之间互相引用

### 延时操作
1. ![](https://pic1.imgdb.cn/item/6788d713d0e0a243d4f4d90b.png)
2. 并不是定时操作的概念-延时操作需要延时返回响应的结果
3. 生产者客户端发送消息的时候将 acks 参数设置为-1
   1. 等待 ISR 集合中的所有副本都确认收到消息之后才能正确地收到响应的结果
   2. 或者捕获超时异常
   3. 需要延时操作管理器
4. 延时拉取（DelayedFetch）
   1. 当follower节点已经和leader节点消息相同,再拉取最新消息时,如果一直不停地拉,而且总是收到空的消息,徒耗资源
   2. Kafka 在处理拉取请求时,会先读取一次日志文件,如果收集不到足够多
   3. 会创建一个延时拉取操作（DelayedFetch）以等待拉取到足够数量的消息
   4. 当延时拉取操作执行时,会再读取一次日志文件,然后将拉取结果返回给 follower 副本
5. 延时数据删除（DelayedDeleteRecords）

### 控制器
1. 控制器（Kafka Controller）-在 Kafka 集群中会有一个或多个 broker,其中有一个 broker 会被选举为控制器
   1. 监听分区相关的变化
   2. 监听主题相关的变化
   3. 监听 broker 相关的变化
   4. 从 ZooKeeper 中读取获取当前所有与主题、分区及broker有关的信息并进行相应的管理
   5. 启动并管理分区状态机和副本状态机
   6. 更新集群的元数据信息
   7. 如果参数 auto.leader.rebalance.enable 设置为 true,则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的优先副本的均衡
2. 负责管理整个集群中所有分区和副本的状态
   1. leader副本故障-当某个分区的 leader 副本出现故障时,由控制器负责为该分区选举新的 leader 副本
   2. ISR集合变化-当检测到某个分区的 ISR 集合发生变化时,由控制器负责通知所有broker更新其元数据信息
   3. 增加分区数量-当使用 kafka-topics.sh 脚本为某个 topic 增加分区数量时,同样还是由控制器负责分区的重新分配
3. 控制器选举工作依赖于 ZooKeeper-成功竞选为控制器的 broker 会在 ZooKeeper 中创建 /controller 这个临时（EPHEMERAL）节点
4. 在任意时刻,集群中有且仅有一个控制器
   1. 每个 broker 启动的时候会去尝试读取 /controller 节点的 brokerid 的值
      1. 如果不是-1,则代表已经有控制器节点,放弃竞选
      2. 如果不存在,则尝试去创建 /controller 节点
   2. 每个 broker 都会在内存中保存当前控制器的 brokerid 值,这个值可以标识为 activeControllerId.
5. 保证控制器的唯一性,进而保证相关操作的一致性
   1. /controller_epoch 节点,这个节点是持久（PERSISTENT）节点
       1. 用于记录控制器发生变更的次数,即记录当前的控制器是第几代控制器
       2. 初始值为1,控制器发生变更时,则递增1
   2. 每个和控制器交互的请求都会携带 controller_epoch 这个字段
       1. 如果小于,则认为这个请求是向已经过期的控制器所发送的请求
       2. 如果大于,说明已经有新的控制器当选了
6. 信息同步
   1. 控制器在选举成功之后会读取 ZooKeeper 中各个节点的数据来初始化上下文信息（ControllerContext）
   2. 并且需要管理这些上下文信息,并且需要将这些变更信息同步到其他普通的 broker 节点中
   3. ![](https://pic1.imgdb.cn/item/6788dd19d0e0a243d4f4dbd7.png)
   4. 不同事件都会更新上下文,存在并发问题
      1. 使用锁影响性能
      2. Kafka 的控制器使用单线程基于事件队列的模型
         1. 将每个事件都做一层封装,然后按照事件发生的先后顺序暂存到 LinkedBlockingQueue 中
         2. 使用一个专用的线程（ControllerEventThread）按照 FIFO（First Input First Output,先入先出）的原则顺序处理各个事件
   5. 只有 Kafka Controller 在 ZooKeeper 上注册相应的监听器,其他的 broker 极少需要再监听 ZooKeeper 中的数据变化,减少zookeeper的压力
7. 优雅关闭
   1. kill -9不够优雅,相关资源未释放
   2. Kafka 服务入口程序中有一个名为“kafka-shutdown- hock”的关闭钩子
      1. 待 Kafka 进程捕获终止信号的时候会执行这个关闭钩子中的内容,其中除了正常关闭一些必要的资源,还会执行一个控制关闭（ControlledShutdown）的动作
      2. 优点一是可以让消息完全同步到磁盘上,在服务下次重新上线时不需要进行日志的恢复操作
      3. 优点二是 ControllerShutdown 在关闭服务之前,会对其上的 leader 副本进行迁移,这样就可以减少分区的不可用时间
8. 分区leader的选举
   1. 由控制器负责具体实施
   2. 针对不同case,可以有不同的策略

### 服务端参数

### 消费端分区分配策略
1. RangeAssignor-默认
   1. 按照消费者总数和分区总数进行整除运算来获得一个跨度,然后将分区按照跨度进行平均分配,以保证分区尽可能均匀地分配给所有的消费者
2. RoundRobinAssignor
   1. 通过轮询方式逐个将分区依次分配给每个消费者
3. StickyAssignor
   1. 分区的分配要尽可能均匀
   2. 分区的分配尽可能与上次分配的保持相同
4. 也支持自定义分区分配策略

### 消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）
1. 协同多个消费者之间的分区分配
   1. 一个消费者配置了2个策略
   2. 不同消费者策略不同
   3. 如何协同不同消费者
2. 旧版依赖zookeeper,消费者监听zookeeper路径变化,并没有协调器
   1. 羊群效应-个体跟随大众决策,常见于金融和社交媒体
   2. 脑裂问题-分布式系统中因网络分区导致的不一致状态
3. 再均衡的原理
   1. 将所有的消费者组分为多个子集,每个子集在服务端中对应一个组协调器
   2. 组协调器是 Kafka 服务端中用于管理消费组的组件
   3. 消费者客户端中的消费者协调器组件负责与组协调器进行交互
   4. 负责执行消费者再均衡的操作,包括分区分配的工作也是在再均衡期间完成的
4. 步骤
   1. 第一阶段（FIND_COORDINATOR）
      1. 消费者需要确定它所属的消费组对应的 组协调器 所在的 broker,并创建与该 broker 相互通信的网络连接
   2. 第二阶段（JOIN_GROUP）
      1. 消费者会向 组协调器 发送 JoinGroupRequest 请求
      2. 组协调器选举消费组的leader
      3. 选举分区分配策略
      4. 选票数最多的策略即为当前消费组的分配策略
      5. Kafka 服务端就要发送 JoinGroupResponse 响应给各个消费者
   3. 第三阶段（SYNC_GROUP）
      1. leader 消费者将选举出来的分配策略同步给组协调器
      2. 其他消费者向组协调器获取分配策略
      3. 服务端把消费者的元数据存储起来,并返回响应
   4. 第四阶段（HEARTBEAT）
      1. 消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系,以及它们对分区的所有权关系
      2. 心跳线程是一个独立的线程,可以在轮询消息的空档发送心跳

### 事务
1. 消息传输的3个层次
   1. at most once：至多一次.消息可能会丢失,但绝对不会重复传输
   2. at least once：最少一次.消息绝不会丢失,但可能会重复传输
   3. exactly once：恰好一次.每条消息肯定会被传输一次且仅传输一次.
2. 引入了幂等和事务这两个特性,以此来实现 EOS（exactly once semantics,精确一次处理语义）
3. 幂等
   1. 生产者客户端参数 enable.idempotence 设置为 true,默认 false
   2. 引入了 producer id（以下简称 PID）和序列号（sequence number）这两个概念
      1. 每个新的生产者实例在初始化的时候都会被分配一个 PID
      2. 对于每个 PID,消息发送到的每一个分区都有对应的序列号,这些序列号从0开始单调递增
      3. 生产者每发送一条消息就会将 <PID,分区> 对应的序列号的值加1
      4. broker 端会在内存中为每一对 <PID,分区> 维护一个序列号-通过比较当前值与消息中的值来确定该消息是否正确
      5. 幂等只保证单生产者的单分区-引入序列号来实现幂等也只是针对每一对 <PID,分区> 而言的,Kafka 的幂等只能保证单个生产者会话（session）中单分区的幂等
4. 事务
   1. 事务可以保证对多个分区写入操作的原子性
   2. 典型的应用模式为“consume-transform-produce”
      1. 应用程序必须提供唯一的 transactionalId
      2. transactionalId 与 PID 一一对应
         1. transactionalId 由用户显式设置,而 PID 是由 Kafka 内部分配的
      3. 从消费者的角度分析,事务能保证的语义相对偏弱
         1. 对采用日志压缩策略的主题而言,事务中的某些消息有可能被清理（相同key的消息,后写入的消息会覆盖前面写入的消息）
         2. 事务中消息可能分布在同一个分区的多个日志分段（LogSegment）中,当老的日志分段被删除时,对应的消息可能会丢失
         3. 消费者可以通过 seek() 方法访问任意 offset 的消息,从而可能遗漏事务中的部分消息
         4. 消费者在消费时可能没有分配到事务内的所有分区,如此它也就不能读取事务中的所有消息
      4. 事务等级-isolation.level
         1. 默认值为“read_uncommitted”-未提交读-消费端应用可以看到（消费到）未提交的事务
         2. “read_committed”-提交读-消费端应用不可以看到尚未提交的事务内的消息
   3. 引入了事务协调器（TransactionCoordinator）来负责处理事务-类似于组协调器

### 多副本机制
1. 实现水平扩展、提供容灾能力、提升可用性和可靠性
2. 副本剖析
   1. 副本是相对于分区而言的,即副本是特定分区的副本
   2. 一个分区中包含一个或多个副本,其中一个为 leader 副本,其余为 follower 副本,各个副本位于不同的 broker 节点中.只有 leader 副本对外提供服务,follower 副本只负责数据同步
   3. 分区中的所有副本统称为 AR,而 ISR 是指与 leader 副本保持同步状态的副本集合,当然 leader 副本本身也是这个集合中的一员
   4. LEO 标识每个分区中最后一条消息的下一个位置,分区的每个副本都有自己的 LEO,ISR 中最小的 LEO 即为 HW,俗称高水位,消费者只能拉取到 HW 之前的消息
   5. 失效副本
      1. 同步失效或功能失效
      2. Kafka 的副本管理器会启动一个副本过期检测的定时任务
   6. ISR的伸缩
      1. Kafka 在启动的时候会开启两个与ISR相关的定时任务,名称分别为“isr-expiration”和“isr-change-propagation”
      2. isr-expiration 任务会周期性地检测每个分区是否需要缩减其 ISR 集合-将变更后的数据记录到 ZooKeeper
      3. 当 ISR 集合发生变更时还会将变更后的记录缓存到 isrChangeSet 中
         1. isr-change-propagation 任务会周期性（固定值为 2500ms）地检查 isrChangeSet
         2. 将数据记录到zookeeper
         3. Kafka 控制器为该节点有一个watcher
            1. 当数据有变化时候
            2. 通知控制器更新相关元数据信息并向它管理的 broker 节点发送更新元数据的请求
         4. 有一定的条件
            1. 上一次 ISR 集合发生变化距离现在已经超过5s
            2. 上一次写入 ZooKeeper 的时间距离现在已经超过60s.
   7. 本地副本（Local Replica）和远程副本（Remote Replica）-参考系不同
3. Leader Epoch机制
   1. 多副本同步机制在部分重启,宕机时会出现数据不一致或丢失问题-如果只使用HW作为同步机制
   2. 需要截断数据的时候使用 leader epoch 作为参考依据而不是原本的 HW
   3. leader epoch 代表 leader 的纪元信息（epoch）,初始值为0.每当 leader 变更一次,leader epoch 的值就会加1,相当于为 leader 增设了一个版本号
4. 为什么不支持读写分离
   1. 代码复杂度提高
   2. 数据一致性问题
   3. 延时问题/多次I/O
   4. 多分区机制能实现一部分的负载均衡
   5. 在实际应用中,还需要配合监控、告警、运维相结合的生态平台
   6. 最新版的kafka已经支持读写分离,不过是在特定场景下-地理复制-多数据中心部署-冷热数据分离

### 可靠性
1. 日志同步机制
   1. 根据使用需求,进行权衡
   2. 基本是使用少数服从多数
   3. 写入消息时只有等到所有ISR集合中的副本都确认收到之后才能被认为已经提交
   4. 位于 ISR 中的任何副本节点都有资格成为 leader,选举过程简单、开销低
2. 可靠性分析
   1. 设置副本数为3即可满足绝大多数场景对可靠性的要求
   2. 生产者客户端参数 acks-决定需要几个副本确认同步完成
   3. 消息发送有3种模式,即发后即忘、同步和异步
   4. 生产者重试次数与重试时间间隔
   5. 消费位移的提交方式设置
   6. kafka支持回溯消费

### 扩展
1. 过期时间（TTL）-通过在消息头中自定义设置,消费者拦截器中进行判断处理
2. 延时队列
   1. 原生的 Kafka 并不具备延时队列的功能
   2. 方案一:建了多个不同时间间隔的内部主题,生产者根据延时不同进行投递,再通过自定义服务拉取再重新生产消息给消费者存在一定的时间误差,也对服务端的内存有一定的影响
   3. 更加精确-利用时间轮概念建立一个延时模块,每个时间格代表一个文件,同时也使用多副本方案
3. 死信队列和重试队列
   1. 为异常处理提供的一种机制保障
   2. 死信队列:消费者无法处理或不想处理的消息,kafka原生不支持
   3. 重试队列:其实可以看作一种回退队列,具体指消费端消费消息失败时,为了防止消息无故丢失而重新将消息回滚到 broker 中有多个等级,每个等级的延迟时间加长
4. 消息路由-原生不包含,可以通过生产时在消息头中设置,然后在消费者拦截器中进行判断
5. 消息轨迹-通过特定的内部主题来存储
6. 消息审计-通过在消息体（value 字段）或在消息头（headers 字段）中内嵌消息对应的时间戳 timestamp 或全局的唯一标识 ID（或者是两者兼备）来实现消息的审计功能
7. 消息中间件选型分析
   1. 功能维度
   2. 性能维度-kafka比RabbitMQ高1,2个数量级
   3. 可靠性和可用性
      1. Kafka 采用的是类似 PacificA 的一致性协议,通过 ISR（In-Sync-Replica）来保证多副本之间的同步,并且支持强一致性语义（通过 acks 实现）
      2. RabbitMQ 是通过镜像环形队列实现多副本及强一致性语义的
   4. 运维管理
   5. 社区力度及生态发展

## 其他消息组件
1. pulsar与kafka
   1. 共同点
      1. 分布式架构
      2. 消息持久化
      3. 高吞吐
      4. 多种编程语言支持
      5. 消息分区
      6. 消费组
   2. 不同点
      1. 架构设计
         1. Kafka：采用分区日志架构,每个分区是一个有序的日志文件
         2. Pulsar：采用分层架构,计算与存储分离,使用 BookKeeper 进行消息存储
      2. 消息模型
         1. Kafka：主要支持发布/订阅模型
         2. Pulsar：支持发布/订阅和队列模型,提供更灵活的消息处理方式
      3. 消息保留
         1. Kafka：消息保留基于时间或大小,过期后删除
         2. Pulsar：支持更灵活的消息保留策略,允许按需保留
      4. 多租户支持
         1. Kafka：多租户支持较弱,通常通过集群隔离实现
         2. Pulsar：原生支持多租户,适合多团队、多应用场景
      5. 地理复制
         1. Kafka：通过 MirrorMaker 实现跨数据中心复制,配置较复杂
         2. Pulsar：内置地理复制功能,配置简单
      6. 延迟消息
         1. Kafka：不支持延迟消息
         2. Pulsar：支持延迟消息,适合定时任务等场景
      7. 扩展性
         1. Kafka：扩展性较好,但受限于分区数量
         2. Pulsar：计算与存储分离,扩展性更强,适合大规模部署
      8. 生态系统
         1. Kafka：生态系统成熟,拥有丰富的工具和插件
         2. Pulsar：生态系统正在快速发展,但相比 Kafka 仍有一定差距
   3. 特点
      1. 计算与存储分离：Broker 负责消息传递,BookKeeper 负责消息存储,这种设计提高了系统的扩展性和灵活性
      2. 多副本存储：通过 BookKeeper 实现多副本存储,确保消息的高可用性和持久性

2. rocketMq
